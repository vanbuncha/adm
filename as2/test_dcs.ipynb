{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discrete cosine similiarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse import coo_matrix\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import save_npz\n",
    "from scipy.sparse import load_npz\n",
    "from datasketch import MinHash\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSR format sparse matrix:\n",
      "  (0, 0)\t1\n",
      "  (0, 1)\t30\n",
      "  (0, 2)\t3\n",
      "  (1, 0)\t1\n",
      "  (1, 1)\t157\n",
      "  (1, 2)\t3\n",
      "  (2, 0)\t1\n",
      "  (2, 1)\t173\n",
      "  (2, 2)\t4\n",
      "  (3, 0)\t1\n",
      "  (3, 1)\t175\n",
      "  (3, 2)\t5\n",
      "  (4, 0)\t1\n",
      "  (4, 1)\t191\n",
      "  (4, 2)\t2\n",
      "  (5, 0)\t1\n",
      "  (5, 1)\t197\n",
      "  (5, 2)\t3\n",
      "  (6, 0)\t1\n",
      "  (6, 1)\t241\n",
      "  (6, 2)\t3\n",
      "  (7, 0)\t1\n",
      "  (7, 1)\t295\n",
      "  (7, 2)\t4\n",
      "  (8, 0)\t1\n",
      "  :\t:\n",
      "  (65225497, 2)\t3\n",
      "  (65225498, 0)\t103703\n",
      "  (65225498, 1)\t17330\n",
      "  (65225498, 2)\t2\n",
      "  (65225499, 0)\t103703\n",
      "  (65225499, 1)\t17346\n",
      "  (65225499, 2)\t4\n",
      "  (65225500, 0)\t103703\n",
      "  (65225500, 1)\t17424\n",
      "  (65225500, 2)\t4\n",
      "  (65225501, 0)\t103703\n",
      "  (65225501, 1)\t17479\n",
      "  (65225501, 2)\t2\n",
      "  (65225502, 0)\t103703\n",
      "  (65225502, 1)\t17621\n",
      "  (65225502, 2)\t4\n",
      "  (65225503, 0)\t103703\n",
      "  (65225503, 1)\t17622\n",
      "  (65225503, 2)\t2\n",
      "  (65225504, 0)\t103703\n",
      "  (65225504, 1)\t17627\n",
      "  (65225504, 2)\t4\n",
      "  (65225505, 0)\t103703\n",
      "  (65225505, 1)\t17764\n",
      "  (65225505, 2)\t4\n"
     ]
    }
   ],
   "source": [
    "# data load and conversion to csr_matrix format\n",
    "data = np.load('data/user_movie_rating.npy')\n",
    "sparse_matrix = csr_matrix(data)\n",
    "\n",
    "# Save the CSR format sparse matrix to a .npz file\n",
    "save_npz('csr_sparse_matrix.npz', sparse_matrix)\n",
    "\n",
    "# Print the CSR format sparse matrix\n",
    "print(\"CSR format sparse matrix:\")\n",
    "print(sparse_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a user_movie matrix\n",
    "\n",
    "data = np.load('data/user_movie_rating.npy')\n",
    "data_array = data.astype(int)\n",
    "\n",
    "# Extract user, movie, and rating data from the loaded records\n",
    "user_ids, movie_ids, ratings = data[:, 0], data[:, 1], data[:, 2]\n",
    "\n",
    "# Create a CSR \n",
    "user_movie_matrix = csr_matrix((ratings, (user_ids, movie_ids)))\n",
    "\n",
    "\n",
    "# Load the user-movie ratings data from the npz file\n",
    "num_users = user_movie_matrix.shape[0]\n",
    "num_movies = user_movie_matrix.shape[1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minhashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_movie_matrix = csr_matrix((ratings, (user_ids, movie_ids)))\n",
    "\n",
    "# Number of hash functions for MinHashing\n",
    "n = 150\n",
    "\n",
    "# Create an array to store MinHash signatures for each user\n",
    "minhash_signatures = []\n",
    "\n",
    "# Function to generate MinHash signatures for a set of movie ratings\n",
    "def generate_minhash_signature(ratings):\n",
    "    minhash = MinHash(num_perm=n)\n",
    "    for movie_id in ratings.nonzero()[1]:\n",
    "        minhash.update(str(movie_id).encode('utf-8'))\n",
    "    return minhash\n",
    "\n",
    "# Generate MinHash signatures for each user\n",
    "for user_id in range(num_users):\n",
    "    user_ratings = user_movie_matrix.getrow(user_id)\n",
    "    minhash_signature = generate_minhash_signature(user_ratings)\n",
    "    minhash_signatures.append(minhash_signature)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  LSH with Minhash Signatures\n",
    "\n",
    "# number of bands (b) and rows per band (r)\n",
    "b = 10  # number of partitions\n",
    "r = 15 # ensure that r * b = n\n",
    "\n",
    "# initialize a dictionary to store buckets\n",
    "buckets = {}\n",
    "\n",
    "# hash Minhash signatures into bands\n",
    "for user_id in range(num_users):\n",
    "    minhash_signature = minhash_signatures[user_id]\n",
    "    for band_id in range(b):\n",
    "        band_start = band_id * r\n",
    "        band_end = (band_id + 1) * r\n",
    "        band_signature = minhash_signature.hashvalues[band_start:band_end]\n",
    "        \n",
    "        # convert the band signature to a hashable string using hash function\n",
    "        band_signature_str = str(band_signature)\n",
    "        \n",
    "        # add the user to the corresponding bucket\n",
    "        if band_signature_str not in buckets:\n",
    "            buckets[band_signature_str] = []\n",
    "        buckets[band_signature_str].append(user_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pair generation\n",
    "user_ids, movie_ids = user_movie_matrix.nonzero()\n",
    "\n",
    "# Initialize a list to store candidate pairs of users\n",
    "candidate_pairs = []\n",
    "\n",
    "# Iterate through the buckets created in LSH\n",
    "for bucket in buckets.values():\n",
    "    # Generate pairs of users within each bucket\n",
    "    for i in range(len(bucket)):\n",
    "        for j in range(i + 1, len(bucket)):\n",
    "            user1 = bucket[i]\n",
    "            user2 = bucket[j]\n",
    "\n",
    "            # Check for common movie ratings\n",
    "            common_movies = set(movie_ids[user_movie_matrix[user1].nonzero()[1]]) & set(movie_ids[user_movie_matrix[user2].nonzero()[1]])\n",
    "            \n",
    "            # Include the pair only if there is at least one common movie\n",
    "            if common_movies:\n",
    "                candidate_pairs.append((user1, user2))\n",
    "\n",
    "# Remove duplicate pairs\n",
    "candidate_pairs = list(set(candidate_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pairs with DCS > 0.73: 36\n"
     ]
    }
   ],
   "source": [
    "#  DCS Calculation and Threshold Check\n",
    "\n",
    "# define the threshold for DCS\n",
    "threshold_dcs = 0.73  \n",
    "\n",
    "# initialize a list to store pairs of users with high DCS\n",
    "users_dcs= []\n",
    "\n",
    "# Calculate DCS between two Minhash signatures\n",
    "def calculate_dcs(minhash_signature1, minhash_signature2):\n",
    "    # Extract the hash values from the Minhash signatures\n",
    "    hash_values1 = minhash_signature1.hashvalues\n",
    "    hash_values2 = minhash_signature2.hashvalues\n",
    "\n",
    "    # Ensure the hash values have the same length\n",
    "    min_length = min(len(hash_values1), len(hash_values2))\n",
    "    hash_values1 = hash_values1[:min_length]\n",
    "    hash_values2 = hash_values2[:min_length]\n",
    "\n",
    "    # Check for zero-length vectors\n",
    "    if min_length == 0:\n",
    "        return 0.0\n",
    "\n",
    "    # Calculate the discrete cosine similarity\n",
    "    dot_product = np.dot(hash_values1, hash_values2)\n",
    "    norm1 = np.linalg.norm(hash_values1)\n",
    "    norm2 = np.linalg.norm(hash_values2)\n",
    "\n",
    "    # Calculate DCS value\n",
    "    dcs = dot_product / (norm1 * norm2) if (norm1 * norm2) > 0 else 0.0\n",
    "\n",
    "    return dcs\n",
    "\n",
    "    \n",
    "# Iterate through the candidate pairs\n",
    "for user1, user2 in candidate_pairs:\n",
    "    # Retrieve the Minhash signatures for user1 and user2\n",
    "    minhash_signature1 = minhash_signatures[user1]\n",
    "    minhash_signature2 = minhash_signatures[user2]\n",
    "\n",
    "    # Calculate DCS between the Minhash signatures\n",
    "    dcs = calculate_dcs(minhash_signature1, minhash_signature2)\n",
    "\n",
    "    # Debugging: Print user IDs, DCS value, and Minhash signatures\n",
    "    # print(f\"User IDs: {user1}, {user2}, DCS: {dcs}\")\n",
    "    # print(f\"Minhash Signature 1: {minhash_signature1}\")\n",
    "    # print(f\"Minhash Signature 2: {minhash_signature2}\")\n",
    "\n",
    "    # Check if DCS exceeds the threshold\n",
    "    if dcs > threshold_dcs:\n",
    "        users_dcs.append((user1, user2))\n",
    "\n",
    "# Print the total number of pairs with DCS > threshold\n",
    "print(f\"Total pairs with DCS > {threshold_dcs}: {len(users_dcs)}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Output for DCS\n",
    "\n",
    "# # Define the output file name\n",
    "# output_file = \"similar_user_pairs_dcs.txt\"\n",
    "\n",
    "# # write similar user pairs to the output file\n",
    "# with open(output_file, \"w\") as file:\n",
    "#     for user1, user2 in users_dcs:\n",
    "#         # write the user pair (u1, u2) to the file\n",
    "#         file.write(f\"{user1},{user2}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For 80 hash functions, b=7 and r=11, total pairs with DCS > 0.73: 731\n",
      "For 90 hash functions, b=8 and r=11, total pairs with DCS > 0.73: 737\n",
      "For 100 hash functions, b=9 and r=7, total pairs with DCS > 0.73: 101575\n",
      "For 110 hash functions, b=9 and r=12, total pairs with DCS > 0.73: 501\n",
      "For 120 hash functions, b=10 and r=11, total pairs with DCS > 0.73: 913\n",
      "For 130 hash functions, b=11 and r=11, total pairs with DCS > 0.73: 1206\n",
      "For 140 hash functions, b=12 and r=11, total pairs with DCS > 0.73: 1299\n",
      "For 150 hash functions, b=13 and r=11, total pairs with DCS > 0.73: 1311\n"
     ]
    }
   ],
   "source": [
    "# Values for b*r corresponding to different hash function totals\n",
    "br_equivalents = {\n",
    "    80: (7, 11),\n",
    "    90: (8, 11),\n",
    "    100: (9, 7),\n",
    "    110: (9,12 ),\n",
    "    120: (10, 11),\n",
    "    130: (11, 11),\n",
    "    140: (12, 11),\n",
    "    150: (13, 11)\n",
    "}\n",
    "\n",
    "# Iterate through the specified values of b*r\n",
    "for total_hash_functions, br_value in br_equivalents.items():\n",
    "    b, r = br_value\n",
    "    \n",
    "    # Ensure r is at least 1\n",
    "    r = max(1, r)\n",
    "    \n",
    "    # Initialize a dictionary to store buckets\n",
    "    buckets = {}\n",
    "\n",
    "    # Hash Minhash signatures into bands\n",
    "    for user_id in range(num_users):\n",
    "        minhash_signature = minhash_signatures[user_id]\n",
    "        for band_id in range(b):\n",
    "            band_start = band_id * r\n",
    "            band_end = (band_id + 1) * r\n",
    "            band_signature = minhash_signature.hashvalues[band_start:band_end]\n",
    "            \n",
    "            # Convert the band signature to a hashable string using hash function\n",
    "            band_signature_str = str(band_signature)\n",
    "            \n",
    "            # Add the user to the corresponding bucket\n",
    "            if band_signature_str not in buckets:\n",
    "                buckets[band_signature_str] = []\n",
    "            buckets[band_signature_str].append(user_id)\n",
    "\n",
    "    # Pair generation\n",
    "    user_ids, movie_ids = user_movie_matrix.nonzero()\n",
    "\n",
    "    # Initialize a list to store candidate pairs of users\n",
    "    candidate_pairs = []\n",
    "\n",
    "    # Iterate through the buckets created in LSH\n",
    "    for bucket in buckets.values():\n",
    "        # Generate pairs of users within each bucket\n",
    "        for i in range(len(bucket)):\n",
    "            for j in range(i + 1, len(bucket)):\n",
    "                user1 = bucket[i]\n",
    "                user2 = bucket[j]\n",
    "\n",
    "                # Check for common movie ratings\n",
    "                common_movies = set(movie_ids[user_movie_matrix[user1].nonzero()[1]]) & set(movie_ids[user_movie_matrix[user2].nonzero()[1]])\n",
    "                \n",
    "                # Include the pair only if there is at least one common movie\n",
    "                if common_movies:\n",
    "                    candidate_pairs.append((user1, user2))\n",
    "\n",
    "    # Remove duplicate pairs\n",
    "    candidate_pairs = list(set(candidate_pairs))\n",
    "\n",
    "    # DCS Calculation and Threshold Check\n",
    "    threshold_dcs = 0.73  # Define the threshold for DCS\n",
    "    users_dcs = []  # Initialize a list to store pairs of users with high DCS\n",
    "\n",
    "    # Iterate through the candidate pairs\n",
    "    for user1, user2 in candidate_pairs:\n",
    "        # Retrieve the Minhash signatures for user1 and user2\n",
    "        minhash_signature1 = minhash_signatures[user1]\n",
    "        minhash_signature2 = minhash_signatures[user2]\n",
    "\n",
    "        # Calculate DCS between the Minhash signatures\n",
    "        dcs = calculate_dcs(minhash_signature1, minhash_signature2)\n",
    "\n",
    "        # Check if DCS exceeds the threshold\n",
    "        if dcs > threshold_dcs:\n",
    "            users_dcs.append((user1, user2))\n",
    "\n",
    "    # Print the total number of pairs with DCS > threshold for each (b, r) combination\n",
    "    print(f\"For {total_hash_functions} hash functions, b={b} and r={r}, total pairs with DCS > {threshold_dcs}: {len(users_dcs)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pairs with Jaccard Similarity > 0.5: 1333\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "# Number of bands and rows\n",
    "b = 13\n",
    "r = 11\n",
    "\n",
    "# Initialize a dictionary to store buckets\n",
    "buckets = {}\n",
    "\n",
    "# Hash Minhash signatures into bands\n",
    "for user_id in range(num_users):\n",
    "    minhash_signature = minhash_signatures[user_id]\n",
    "    for band_id in range(b):\n",
    "        band_start = band_id * r\n",
    "        band_end = (band_id + 1) * r\n",
    "        band_signature = minhash_signature.hashvalues[band_start:band_end]\n",
    "        \n",
    "        # Convert the band signature to a hashable string using hash function\n",
    "        band_signature_str = str(band_signature)\n",
    "        \n",
    "        # Add the user to the corresponding bucket\n",
    "        if band_signature_str not in buckets:\n",
    "            buckets[band_signature_str] = []\n",
    "        buckets[band_signature_str].append(user_id)\n",
    "\n",
    "# Pair generation\n",
    "user_ids, movie_ids = user_movie_matrix.nonzero()\n",
    "\n",
    "# Initialize a list to store candidate pairs of users\n",
    "candidate_pairs = []\n",
    "\n",
    "# Set the threshold for Jaccard Similarity\n",
    "threshold_jaccard = 0.5\n",
    "\n",
    "# Iterate through the buckets created in LSH\n",
    "for bucket in buckets.values():\n",
    "    # Generate pairs of users within each bucket\n",
    "    for user1, user2 in combinations(bucket, 2):\n",
    "        # Check for common movie ratings\n",
    "        common_movies = set(movie_ids[user_movie_matrix[user1].nonzero()[1]]) & set(movie_ids[user_movie_matrix[user2].nonzero()[1]])\n",
    "        \n",
    "        # Calculate Jaccard Similarity\n",
    "        denominator = len(set(movie_ids[user_movie_matrix[user1].nonzero()[1]]) | set(movie_ids[user_movie_matrix[user2].nonzero()[1]]))\n",
    "        jaccard_similarity = len(common_movies) / denominator if denominator != 0 else 0.0\n",
    "        \n",
    "        # Include the pair only if there is at least one common movie and Jaccard Similarity is above the threshold\n",
    "        if common_movies and jaccard_similarity > threshold_jaccard:\n",
    "            candidate_pairs.append((user1, user2, jaccard_similarity))\n",
    "\n",
    "# Print the total number of pairs with Jaccard Similarity above the threshold\n",
    "print(f\"Total pairs with Jaccard Similarity > {threshold_jaccard}: {len(candidate_pairs)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pairs with Cosine Similarity > 0.73: 5315\n"
     ]
    }
   ],
   "source": [
    "# Number of bands and rows\n",
    "b = 13\n",
    "r = 11\n",
    "\n",
    "# Initialize a dictionary to store buckets\n",
    "buckets = {}\n",
    "\n",
    "# Hash Minhash signatures into bands\n",
    "for user_id in range(num_users):\n",
    "    minhash_signature = minhash_signatures[user_id]\n",
    "    for band_id in range(b):\n",
    "        band_start = band_id * r\n",
    "        band_end = (band_id + 1) * r\n",
    "        band_signature = minhash_signature.hashvalues[band_start:band_end]\n",
    "        \n",
    "        # Convert the band signature to a hashable string using hash function\n",
    "        band_signature_str = str(band_signature)\n",
    "        \n",
    "        # Add the user to the corresponding bucket\n",
    "        if band_signature_str not in buckets:\n",
    "            buckets[band_signature_str] = []\n",
    "        buckets[band_signature_str].append(user_id)\n",
    "\n",
    "# Pair generation\n",
    "user_ids, movie_ids = user_movie_matrix.nonzero()\n",
    "\n",
    "# Initialize a list to store candidate pairs of users\n",
    "candidate_pairs = []\n",
    "\n",
    "# Set the threshold for Cosine Similarity\n",
    "threshold_cosine = 0.73\n",
    "\n",
    "# Iterate through the buckets created in LSH\n",
    "for bucket in buckets.values():\n",
    "    # Generate pairs of users within each bucket\n",
    "    for user1, user2 in combinations(bucket, 2):\n",
    "        # Check for common movie ratings\n",
    "        common_movies = set(movie_ids[user_movie_matrix[user1].nonzero()[1]]) & set(movie_ids[user_movie_matrix[user2].nonzero()[1]])\n",
    "        \n",
    "        # Calculate Cosine Similarity\n",
    "        vector1 = np.zeros(len(movie_ids))\n",
    "        vector2 = np.zeros(len(movie_ids))\n",
    "        vector1[list(common_movies)] = 1\n",
    "        vector2[list(common_movies)] = 1\n",
    "        \n",
    "        cosine_similarity = np.dot(vector1, vector2) / (np.linalg.norm(vector1) * np.linalg.norm(vector2)) if (np.linalg.norm(vector1) * np.linalg.norm(vector2)) != 0 else 0.0\n",
    "        \n",
    "        # Include the pair only if there is at least one common movie and Cosine Similarity is above the threshold\n",
    "        if common_movies and cosine_similarity > threshold_cosine:\n",
    "            candidate_pairs.append((user1, user2, cosine_similarity))\n",
    "\n",
    "# Print the total number of pairs with Cosine Similarity above the threshold\n",
    "print(f\"Total pairs with Cosine Similarity > {threshold_cosine}: {len(candidate_pairs)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snacs_as2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
