{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discrete cosine similiarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse import coo_matrix\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import save_npz\n",
    "from scipy.sparse import load_npz\n",
    "from datasketch import MinHash\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSR format sparse matrix:\n",
      "  (0, 0)\t1\n",
      "  (0, 1)\t30\n",
      "  (0, 2)\t3\n",
      "  (1, 0)\t1\n",
      "  (1, 1)\t157\n",
      "  (1, 2)\t3\n",
      "  (2, 0)\t1\n",
      "  (2, 1)\t173\n",
      "  (2, 2)\t4\n",
      "  (3, 0)\t1\n",
      "  (3, 1)\t175\n",
      "  (3, 2)\t5\n",
      "  (4, 0)\t1\n",
      "  (4, 1)\t191\n",
      "  (4, 2)\t2\n",
      "  (5, 0)\t1\n",
      "  (5, 1)\t197\n",
      "  (5, 2)\t3\n",
      "  (6, 0)\t1\n",
      "  (6, 1)\t241\n",
      "  (6, 2)\t3\n",
      "  (7, 0)\t1\n",
      "  (7, 1)\t295\n",
      "  (7, 2)\t4\n",
      "  (8, 0)\t1\n",
      "  :\t:\n",
      "  (65225497, 2)\t3\n",
      "  (65225498, 0)\t103703\n",
      "  (65225498, 1)\t17330\n",
      "  (65225498, 2)\t2\n",
      "  (65225499, 0)\t103703\n",
      "  (65225499, 1)\t17346\n",
      "  (65225499, 2)\t4\n",
      "  (65225500, 0)\t103703\n",
      "  (65225500, 1)\t17424\n",
      "  (65225500, 2)\t4\n",
      "  (65225501, 0)\t103703\n",
      "  (65225501, 1)\t17479\n",
      "  (65225501, 2)\t2\n",
      "  (65225502, 0)\t103703\n",
      "  (65225502, 1)\t17621\n",
      "  (65225502, 2)\t4\n",
      "  (65225503, 0)\t103703\n",
      "  (65225503, 1)\t17622\n",
      "  (65225503, 2)\t2\n",
      "  (65225504, 0)\t103703\n",
      "  (65225504, 1)\t17627\n",
      "  (65225504, 2)\t4\n",
      "  (65225505, 0)\t103703\n",
      "  (65225505, 1)\t17764\n",
      "  (65225505, 2)\t4\n"
     ]
    }
   ],
   "source": [
    "# data load and conversion to csr_matrix format\n",
    "data = np.load('data/user_movie_rating.npy')\n",
    "sparse_matrix = csr_matrix(data)\n",
    "\n",
    "# Save the CSR format sparse matrix to a .npz file\n",
    "save_npz('csr_sparse_matrix.npz', sparse_matrix)\n",
    "\n",
    "# Print the CSR format sparse matrix\n",
    "print(\"CSR format sparse matrix:\")\n",
    "print(sparse_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a user_movie matrix\n",
    "\n",
    "data = np.load('data/user_movie_rating.npy')\n",
    "data_array = data.astype(int)\n",
    "\n",
    "# Extract user, movie, and rating data from the loaded records\n",
    "user_ids, movie_ids, ratings = data[:, 0], data[:, 1], data[:, 2]\n",
    "\n",
    "# Create a CSR \n",
    "user_movie_matrix = csr_matrix((ratings, (user_ids, movie_ids)))\n",
    "\n",
    "\n",
    "# Load the user-movie ratings data from the npz file\n",
    "num_users = user_movie_matrix.shape[0]\n",
    "num_movies = user_movie_matrix.shape[1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minhashing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_movie_matrix = csr_matrix((ratings, (user_ids, movie_ids)))\n",
    "\n",
    "# Number of hash functions for MinHashing\n",
    "n = 100\n",
    "\n",
    "# Create an array to store MinHash signatures for each user\n",
    "minhash_signatures = []\n",
    "\n",
    "# Function to generate MinHash signatures for a set of movie ratings\n",
    "def generate_minhash_signature(ratings):\n",
    "    minhash = MinHash(num_perm=n)\n",
    "    for movie_id in ratings.nonzero()[1]:\n",
    "        minhash.update(str(movie_id).encode('utf-8'))\n",
    "    return minhash\n",
    "\n",
    "# Generate MinHash signatures for each user\n",
    "for user_id in range(num_users):\n",
    "    user_ratings = user_movie_matrix.getrow(user_id)\n",
    "    minhash_signature = generate_minhash_signature(user_ratings)\n",
    "    minhash_signatures.append(minhash_signature)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  LSH with Minhash Signatures\n",
    "\n",
    "# number of bands (b) and rows per band (r)\n",
    "b = 8  # number of partitions\n",
    "r = 11 # ensure that r * b = n\n",
    "\n",
    "# initialize a dictionary to store buckets\n",
    "buckets = {}\n",
    "\n",
    "# hash Minhash signatures into bands\n",
    "for user_id in range(num_users):\n",
    "    minhash_signature = minhash_signatures[user_id]\n",
    "    for band_id in range(b):\n",
    "        band_start = band_id * r\n",
    "        band_end = (band_id + 1) * r\n",
    "        band_signature = minhash_signature.hashvalues[band_start:band_end]\n",
    "        \n",
    "        # convert the band signature to a hashable string using hash function\n",
    "        band_signature_str = str(band_signature)\n",
    "        \n",
    "        # add the user to the corresponding bucket\n",
    "        if band_signature_str not in buckets:\n",
    "            buckets[band_signature_str] = []\n",
    "        buckets[band_signature_str].append(user_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pair generation\n",
    "user_ids, movie_ids = user_movie_matrix.nonzero()\n",
    "\n",
    "# Initialize a list to store candidate pairs of users\n",
    "candidate_pairs = []\n",
    "\n",
    "# Iterate through the buckets created in LSH\n",
    "for bucket in buckets.values():\n",
    "    # Generate pairs of users within each bucket\n",
    "    for i in range(len(bucket)):\n",
    "        for j in range(i + 1, len(bucket)):\n",
    "            user1 = bucket[i]\n",
    "            user2 = bucket[j]\n",
    "\n",
    "            # Check for common movie ratings\n",
    "            common_movies = set(movie_ids[user_movie_matrix[user1].nonzero()[1]]) & set(movie_ids[user_movie_matrix[user2].nonzero()[1]])\n",
    "            \n",
    "            # Include the pair only if there is at least one common movie\n",
    "            if common_movies:\n",
    "                candidate_pairs.append((user1, user2))\n",
    "\n",
    "# Remove duplicate pairs\n",
    "candidate_pairs = list(set(candidate_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pairs with DCS > 0.73: 21\n"
     ]
    }
   ],
   "source": [
    "#  DCS Calculation and Threshold Check\n",
    "\n",
    "# define the threshold for DCS\n",
    "threshold_dcs = 0.73  \n",
    "\n",
    "# initialize a list to store pairs of users with high DCS\n",
    "users_dcs= []\n",
    "\n",
    "# Calculate DCS between two Minhash signatures\n",
    "def calculate_dcs(minhash_signature1, minhash_signature2):\n",
    "    # Extract the hash values from the Minhash signatures\n",
    "    hash_values1 = minhash_signature1.hashvalues\n",
    "    hash_values2 = minhash_signature2.hashvalues\n",
    "\n",
    "    # Ensure the hash values have the same length\n",
    "    min_length = min(len(hash_values1), len(hash_values2))\n",
    "    hash_values1 = hash_values1[:min_length]\n",
    "    hash_values2 = hash_values2[:min_length]\n",
    "\n",
    "    # Check for zero-length vectors\n",
    "    if min_length == 0:\n",
    "        return 0.0\n",
    "\n",
    "    # Calculate the discrete cosine similarity\n",
    "    dot_product = np.dot(hash_values1, hash_values2)\n",
    "    norm1 = np.linalg.norm(hash_values1)\n",
    "    norm2 = np.linalg.norm(hash_values2)\n",
    "\n",
    "    # Calculate DCS value\n",
    "    dcs = dot_product / (norm1 * norm2) if (norm1 * norm2) > 0 else 0.0\n",
    "\n",
    "    return dcs\n",
    "\n",
    "    \n",
    "# Iterate through the candidate pairs\n",
    "for user1, user2 in candidate_pairs:\n",
    "    # Retrieve the Minhash signatures for user1 and user2\n",
    "    minhash_signature1 = minhash_signatures[user1]\n",
    "    minhash_signature2 = minhash_signatures[user2]\n",
    "\n",
    "    # Calculate DCS between the Minhash signatures\n",
    "    dcs = calculate_dcs(minhash_signature1, minhash_signature2)\n",
    "\n",
    "    # Debugging: Print user IDs, DCS value, and Minhash signatures\n",
    "    # print(f\"User IDs: {user1}, {user2}, DCS: {dcs}\")\n",
    "    # print(f\"Minhash Signature 1: {minhash_signature1}\")\n",
    "    # print(f\"Minhash Signature 2: {minhash_signature2}\")\n",
    "\n",
    "    # Check if DCS exceeds the threshold\n",
    "    if dcs > threshold_dcs:\n",
    "        users_dcs.append((user1, user2))\n",
    "\n",
    "# Print the total number of pairs with DCS > threshold\n",
    "print(f\"Total pairs with DCS > {threshold_dcs}: {len(users_dcs)}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output for DCS\n",
    "\n",
    "# Define the output file name\n",
    "output_file = \"similar_user_pairs_dcs.txt\"\n",
    "\n",
    "# write similar user pairs to the output file\n",
    "with open(output_file, \"w\") as file:\n",
    "    for user1, user2 in users_dcs:\n",
    "        # write the user pair (u1, u2) to the file\n",
    "        file.write(f\"{user1},{user2}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For b=1 and r=150, total pairs with DCS > 0.73: 0\n",
      "For b=2 and r=75, total pairs with DCS > 0.73: 0\n"
     ]
    }
   ],
   "source": [
    "# Define the total number of hash functions\n",
    "num_hash_functions = 150\n",
    "\n",
    "# Iterate through different values of b\n",
    "for b in range(1, 11):\n",
    "    # Calculate the corresponding value of r for each b\n",
    "    r = num_hash_functions // b\n",
    "    \n",
    "    # Initialize a dictionary to store buckets\n",
    "    buckets = {}\n",
    "\n",
    "    # Hash Minhash signatures into bands\n",
    "    for user_id in range(num_users):\n",
    "        minhash_signature = minhash_signatures[user_id]\n",
    "        for band_id in range(b):\n",
    "            band_start = band_id * r\n",
    "            band_end = (band_id + 1) * r\n",
    "            band_signature = minhash_signature.hashvalues[band_start:band_end]\n",
    "            \n",
    "            # Convert the band signature to a hashable string using hash function\n",
    "            band_signature_str = str(band_signature)\n",
    "            \n",
    "            # Add the user to the corresponding bucket\n",
    "            if band_signature_str not in buckets:\n",
    "                buckets[band_signature_str] = []\n",
    "            buckets[band_signature_str].append(user_id)\n",
    "\n",
    "    # Pair generation\n",
    "    user_ids, movie_ids = user_movie_matrix.nonzero()\n",
    "\n",
    "    # Initialize a list to store candidate pairs of users\n",
    "    candidate_pairs = []\n",
    "\n",
    "    # Iterate through the buckets created in LSH\n",
    "    for bucket in buckets.values():\n",
    "        # Generate pairs of users within each bucket\n",
    "        for i in range(len(bucket)):\n",
    "            for j in range(i + 1, len(bucket)):\n",
    "                user1 = bucket[i]\n",
    "                user2 = bucket[j]\n",
    "\n",
    "                # Check for common movie ratings\n",
    "                common_movies = set(movie_ids[user_movie_matrix[user1].nonzero()[1]]) & set(movie_ids[user_movie_matrix[user2].nonzero()[1]])\n",
    "                \n",
    "                # Include the pair only if there is at least one common movie\n",
    "                if common_movies:\n",
    "                    candidate_pairs.append((user1, user2))\n",
    "\n",
    "    # Remove duplicate pairs\n",
    "    candidate_pairs = list(set(candidate_pairs))\n",
    "\n",
    "    # DCS Calculation and Threshold Check\n",
    "    threshold_dcs = 0.73  # Define the threshold for DCS\n",
    "    users_dcs = []  # Initialize a list to store pairs of users with high DCS\n",
    "\n",
    "    # Iterate through the candidate pairs\n",
    "    for user1, user2 in candidate_pairs:\n",
    "        # Retrieve the Minhash signatures for user1 and user2\n",
    "        minhash_signature1 = minhash_signatures[user1]\n",
    "        minhash_signature2 = minhash_signatures[user2]\n",
    "\n",
    "        # Calculate DCS between the Minhash signatures\n",
    "        dcs = calculate_dcs(minhash_signature1, minhash_signature2)\n",
    "\n",
    "        # Check if DCS exceeds the threshold\n",
    "        if dcs > threshold_dcs:\n",
    "            users_dcs.append((user1, user2))\n",
    "\n",
    "    # Print the total number of pairs with DCS > threshold for each (b, r) combination\n",
    "    print(f\"For b={b} and r={r}, total pairs with DCS > {threshold_dcs}: {len(users_dcs)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snacs_as2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
