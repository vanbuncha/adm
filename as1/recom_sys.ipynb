{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tasks\n",
    "1. Data Retrieval and Preprocessing\n",
    "- Obtain MovieLens 1M dataset. []\n",
    "- Load dataset. []\n",
    "- Check data integrity: []\n",
    "- Address issues like missing movies. []\n",
    "- Handle data inconsistencies (e.g., user IDs with additional data, ratings for non-existent movies). []\n",
    "- Create User-Item Interaction Matrix. []\n",
    "- Split data for 5-fold cross-validation. []\n",
    "- Handling Cold Starts (dealing with users or items not seen during training). []\n",
    "2. Recommendation Algorithms\n",
    "- Implement Naive Approaches: []\n",
    "- Global Average Rating. []\n",
    "- Average Rating per Item. []\n",
    "- Average Rating per User. []\n",
    "- Optimal Linear Combination with and without bias. []\n",
    "- Implement UV Matrix Decomposition. []\n",
    "- Implement Matrix Factorization with Gradient Descent and Regularization. []\n",
    "- For each algorithm, calculate: \n",
    "- RMSE (Root Mean Squared Error) and MAE (Mean Absolute Error). []\n",
    "- Address Cold Starts for the implemented algorithms. []\n",
    "3. Visualization\n",
    "- Apply dimensionality reduction techniques for visualization: []\n",
    "- PCA (Principal Component Analysis). []\n",
    "- t-SNE (t-Distributed Stochastic Neighbor Embedding). []\n",
    "- UMAP (Uniform Manifold Approximation and Projection). []\n",
    "4. Documentation and Reporting \n",
    "- Document code, algorithms, and preprocessing steps. []\n",
    "- Summarize and analyze the results of each algorithm. []\n",
    "- Provide insights into the best-performing algorithms. []\n",
    "- Discuss challenges and limitations encountered during the implementation. []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as sklearn\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "# import umap\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data retrival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data sets\n",
    "\n",
    "# movies\n",
    "df_movies = pd.read_csv(\"ml-1m/movies.dat\", sep='::', encoding='ISO-8859-1', header=None, engine='python', names=['MovieID', 'Title', 'Genres'])\n",
    "df_movies = df_movies.rename({0: 'MovieID', 1: 'Title', 2: 'Genre'}, axis='columns')\n",
    "\n",
    "#ratings\n",
    "df_ratings = pd.read_csv(\"ml-1m/ratings.dat\", sep='::', encoding='ISO-8859-1', header=None, engine='python', names=['UserID', 'MovieID', 'Rating', 'Timestamp'])\n",
    "\n",
    "#users\n",
    "df_users = pd.read_csv(\"ml-1m/users.dat\", sep='::', encoding='ISO-8859-1', header=None, engine=\"python\", names=['UserID', 'Gender', 'Age', 'Occupation', 'ZipCode'])\n",
    "df_users.columns = ['UserID', 'Gender', 'Age', 'Occupation', 'ZipCode']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UserID        0\n",
       "Gender        0\n",
       "Age           0\n",
       "Occupation    0\n",
       "ZipCode       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values in ratings dataset\n",
    "df_ratings.isnull().sum()\n",
    "\n",
    "# Check for missing values in movies dataset\n",
    "df_movies.isnull().sum()\n",
    "\n",
    "# Check for missing values in users dataset\n",
    "df_users.isnull().sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   MovieID                               Title                        Genres\n",
      "0        1                    Toy Story (1995)   Animation|Children's|Comedy\n",
      "1        2                      Jumanji (1995)  Adventure|Children's|Fantasy\n",
      "2        3             Grumpier Old Men (1995)                Comedy|Romance\n",
      "3        4            Waiting to Exhale (1995)                  Comedy|Drama\n",
      "4        5  Father of the Bride Part II (1995)                        Comedy\n",
      "   UserID  MovieID  Rating  Timestamp\n",
      "0       1     1193       5  978300760\n",
      "1       1      661       3  978302109\n",
      "2       1      914       3  978301968\n",
      "3       1     3408       4  978300275\n",
      "4       1     2355       5  978824291\n",
      "   UserID Gender  Age  Occupation ZipCode\n",
      "0       1      F    1          10   48067\n",
      "1       2      M   56          16   70072\n",
      "2       3      M   25          15   55117\n",
      "3       4      M   45           7   02460\n",
      "4       5      M   25          20   55455\n"
     ]
    }
   ],
   "source": [
    "# Checking data integrity\n",
    "\n",
    "# movies\n",
    "print(df_movies.head())\n",
    "print\n",
    "\n",
    "# ratings\n",
    "print(df_ratings.head())\n",
    "print\n",
    "\n",
    "# users\n",
    "\n",
    "print(df_users.head())\n",
    "\n",
    "# In movies.dat there is missing movieID of 91 we create a placeholder\n",
    "new_movie = pd.DataFrame({'MovieID': [91], 'Title': ['Unknown'], 'Genres': ['Unknown']})\n",
    "df_movies = pd.concat([df_movies, new_movie], ignore_index=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User-item interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - Train Users: 4832, Test Users: 1208\n",
      "Fold 2 - Train Users: 4832, Test Users: 1208\n",
      "Fold 3 - Train Users: 4832, Test Users: 1208\n",
      "Fold 4 - Train Users: 4832, Test Users: 1208\n",
      "Fold 5 - Train Users: 4832, Test Users: 1208\n"
     ]
    }
   ],
   "source": [
    "# Users split into 5\n",
    "\n",
    "num_folds = 5\n",
    "\n",
    "# Kfold object to split data into\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Convert the DataFrame to a list to ensure consistent indices\n",
    "user_data = df_users.values\n",
    "ratings_data = df_ratings.values\n",
    "\n",
    "# Split the data into 5 folds\n",
    "for fold, (train_indices, test_indices) in enumerate(kf.split(user_data)):\n",
    "    # Split the users dataset\n",
    "    train_users = df_users.iloc[train_indices]\n",
    "    test_users = df_users.iloc[test_indices]\n",
    "\n",
    "    # Split the ratings dataset\n",
    "    train_ratings = df_ratings[df_ratings['UserID'].isin(train_users['UserID'])]\n",
    "    test_ratings = df_ratings[df_ratings['UserID'].isin(test_users['UserID'])]\n",
    "\n",
    "    print(f\"Fold {fold + 1} - Train Users: {len(train_users)}, Test Users: {len(test_users)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - Train Movies: 3107, Test Movies: 777\n",
      "Fold 2 - Train Movies: 3107, Test Movies: 777\n",
      "Fold 3 - Train Movies: 3107, Test Movies: 777\n",
      "Fold 4 - Train Movies: 3107, Test Movies: 777\n",
      "Fold 5 - Train Movies: 3108, Test Movies: 776\n"
     ]
    }
   ],
   "source": [
    "# Movie split into 5\n",
    "num_folds = 5\n",
    "\n",
    "# Kfold object to split data into\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Convert the DataFrame to a list to ensure consistent indices\n",
    "movie_data = df_movies.values\n",
    "\n",
    "# Split the data into 5 folds\n",
    "for fold, (train_indices, test_indices) in enumerate(kf.split(movie_data)):\n",
    "    # Split the movies dataset\n",
    "    train_movies = df_movies.iloc[train_indices]\n",
    "    test_movies = df_movies.iloc[test_indices]\n",
    "\n",
    "    print(f\"Fold {fold + 1} - Train Movies: {len(train_movies)}, Test Movies: {len(test_movies)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - Train Ratings: 800167, Test Ratings: 200042\n",
      "Fold 2 - Train Ratings: 800167, Test Ratings: 200042\n",
      "Fold 3 - Train Ratings: 800167, Test Ratings: 200042\n",
      "Fold 4 - Train Ratings: 800167, Test Ratings: 200042\n",
      "Fold 5 - Train Ratings: 800168, Test Ratings: 200041\n"
     ]
    }
   ],
   "source": [
    "# Ratins into 5\n",
    "num_folds = 5\n",
    "\n",
    "# Kfold object to split data into\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Convert the DataFrame to a list to ensure consistent indices\n",
    "ratings_data = df_ratings.values\n",
    "\n",
    "# Split the data into 5 folds\n",
    "for fold, (train_indices, test_indices) in enumerate(kf.split(ratings_data)):\n",
    "    # Split the ratings dataset\n",
    "    train_ratings = df_ratings.iloc[train_indices]\n",
    "    test_ratings = df_ratings.iloc[test_indices]\n",
    "\n",
    "    print(f\"Fold {fold + 1} - Train Ratings: {len(train_ratings)}, Test Ratings: {len(test_ratings)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendations algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   UserID  MovieID  Rating  Timestamp\n",
      "0       1     1193       5  978300760\n",
      "1       1      661       3  978302109\n",
      "2       1      914       3  978301968\n",
      "3       1     3408       4  978300275\n",
      "4       1     2355       5  978824291\n",
      "   UserID Gender  Age  Occupation Zip-code\n",
      "0       1      F    1          10    48067\n",
      "1       2      M   56          16    70072\n",
      "2       3      M   25          15    55117\n",
      "3       4      M   45           7    02460\n",
      "4       5      M   25          20    55455\n",
      "   MovieID                               Title                         Genre\n",
      "0        1                    Toy Story (1995)   Animation|Children's|Comedy\n",
      "1        2                      Jumanji (1995)  Adventure|Children's|Fantasy\n",
      "2        3             Grumpier Old Men (1995)                Comedy|Romance\n",
      "3        4            Waiting to Exhale (1995)                  Comedy|Drama\n",
      "4        5  Father of the Bride Part II (1995)                        Comedy\n",
      "3.581564453029317\n",
      "   MovieID    R_item\n",
      "0        1  4.146846\n",
      "1        2  3.201141\n",
      "2        3  3.016736\n",
      "3        4  2.729412\n",
      "4        5  3.006757\n",
      "   UserID    R_user\n",
      "0       1  4.188679\n",
      "1       2  3.713178\n",
      "2       3  3.901961\n",
      "3       4  4.190476\n",
      "4       5  3.146465\n",
      "   UserID  MovieID  Rating  Timestamp    R_item    R_user\n",
      "0       1     1193       5  978300760  4.390725  4.188679\n",
      "1       1      661       3  978302109  3.464762  4.188679\n",
      "2       1      914       3  978301968  4.154088  4.188679\n",
      "3       1     3408       4  978300275  3.863878  4.188679\n",
      "4       1     2355       5  978824291  3.854375  4.188679\n",
      "alpha: 0.8757397042785027, beta: 0.7821285278627494, gamma: -2.3561974750143455\n"
     ]
    }
   ],
   "source": [
    "class recommenderSystem():\n",
    "\n",
    "\n",
    "    def Naive_1(self, df_ratings):\n",
    "        # Naive Approach\n",
    "        r_global = df_ratings['Rating'].mean()\n",
    "        r_item = df_ratings.groupby('MovieID')['Rating'].mean().reset_index().rename({'Rating':\n",
    "                                                                                      'R_item'},axis='columns')\n",
    "        \n",
    "        r_user = df_ratings.groupby('UserID')['Rating'].mean().reset_index().rename({'Rating': 'R_user'},axis='columns')\n",
    "        df_ratings=df_ratings.merge(r_item, on=['MovieID']).merge(r_user, on=['UserID'])\n",
    "        print(r_global)\n",
    "        print(r_item.head())\n",
    "        print(r_user.head())\n",
    "        print(df_ratings.head())\n",
    "\n",
    "        X = df_ratings[['R_item','R_user']]\n",
    "        y = df_ratings['Rating']\n",
    "        model = LinearRegression().fit(X, y)\n",
    "\n",
    "        alpha, beta = model.coef_\n",
    "        gamma = model.intercept_\n",
    "\n",
    "        print(f'alpha: {alpha}, beta: {beta}, gamma: {gamma}')\n",
    "        \n",
    "    def function_3(self, train):\n",
    "        print(\"hi\")\n",
    "        # The UV matrix decomposition\n",
    "\n",
    "    def function_4(self, train):\n",
    "        # The Matrix Factorization\n",
    "        print(\"yo\")\n",
    "        \n",
    "    def function_5(self, train):\n",
    "        print(\"world\")\n",
    "        \n",
    "    def visualisation_1(self):\n",
    "        # Apply PCA\n",
    "        pca = PCA(n_components=2)\n",
    "        pca_result = pca.fit_transform(data)\n",
    "        \n",
    "    def visualisation_2(self):\n",
    "        # Apply t-SNE\n",
    "        tsne = TSNE(n_components=2, verbose=1)\n",
    "        tsne_result = tsne.fit_transform(data)\n",
    "        \n",
    "    def visualisation_3(self):\n",
    "        # Apply UMAP\n",
    "        umap_model = umap.UMAP(n_components=2)\n",
    "        umap_result = umap_model.fit_transform(data)\n",
    "\n",
    "    def cross_validation(self,folds):\n",
    "        # prepare cross validation\n",
    "        kfold = KFold(folds, True, 1)\n",
    "        train_list=[]\n",
    "        test_list=[]\n",
    "        # enumerate splits\n",
    "        for train, test in kfold.split(self.data):\n",
    "         train_list.append(data[train])\n",
    "         test_list.append(data[test])\n",
    "        return train_list, test_list\n",
    "    \n",
    "    def perf_measures(y_true,y_pred):\n",
    "        # Calculate RMSE (Root Mean Squared Error)\n",
    "        rmse = sqrt(mean_squared_error(y_true, y_pred))\n",
    "        print(f'RMSE: {rmse}')\n",
    "\n",
    "        # Calculate MAE (Mean Absolute Error)\n",
    "        mae = mean_absolute_error(y_true, y_pred)\n",
    "        print(f'MAE: {mae}')\n",
    "        \n",
    "    def main():\n",
    "        train_list,test_list=self.cross_validartion(5)\n",
    "        \n",
    "            \n",
    "        \n",
    "if __name__ == '__main__':\n",
    "            # Specify the file path\n",
    "        file_path = 'ml-1m/ratings.dat'\n",
    "        df_ratings = pd.read_csv(file_path, sep='::',header=None, engine='python')\n",
    "        df_ratings = df_ratings.rename({0: 'UserID',\n",
    "                                        1:'MovieID',\n",
    "                                        2:'Rating',\n",
    "                                        3:'Timestamp'},axis='columns')\n",
    "\n",
    "        print(df_ratings.head())\n",
    "        # Specify the file path\n",
    "        file_path = 'ml-1m/users.dat'\n",
    "        df_users = pd.read_csv(file_path, sep='::',header=None, engine='python')\n",
    "        df_users = df_users.rename({0: 'UserID',\n",
    "                                        1:'Gender',\n",
    "                                        2:'Age',\n",
    "                                        3:'Occupation',\n",
    "                                        4: 'Zip-code'\n",
    "                                        },axis='columns')\n",
    "        print(df_users.head())\n",
    "        # Specify the file path\n",
    "        file_path = 'ml-1m/movies.dat'\n",
    "        df_movies = pd.read_csv(file_path, sep='::', header=None, encoding='ISO-8859-1', engine='python')\n",
    "        df_movies = df_movies.rename({0: 'MovieID',\n",
    "                                        1:'Title',\n",
    "                                        2:'Genre'},axis='columns')\n",
    "\n",
    "\n",
    "        print(df_movies.head())\n",
    "\n",
    "        rec= recommenderSystem()\n",
    "        rec.Naive_1(df_ratings)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "as1_adm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
